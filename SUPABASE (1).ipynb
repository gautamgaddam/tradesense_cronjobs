{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1cd3f5-aeab-482a-8415-bb125957b6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LOADING DATA TO supabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f36672-e735-4b73-9159-8d40978b0860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Largecap = ['ABB.NS', 'ADANIENSOL.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'ATGL.NS', 'AMBUJACEM.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'DMART.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BAJAJHLDNG.NS', 'BANKBARODA.NS', 'BEL.NS', 'BHEL.NS', 'BPCL.NS', 'BHARTIARTL.NS', 'BOSCHLTD.NS', 'BRITANNIA.NS', 'CANBK.NS', 'CHOLAFIN.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DLF.NS', 'DABUR.NS', 'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'GAIL.NS', 'GODREJCP.NS', 'GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HAVELLS.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HAL.NS', 'HINDUNILVR.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'ITC.NS', 'IOC.NS', 'IRCTC.NS', 'IRFC.NS', 'INDUSINDBK.NS', 'NAUKRI.NS', 'INFY.NS', 'INDIGO.NS', 'JSWENERGY.NS', 'JSWSTEEL.NS', 'JINDALSTEL.NS', 'JIOFIN.NS', 'KOTAKBANK.NS', 'LTIM.NS', 'LT.NS', 'LICI.NS', 'LODHA.NS', 'M&M.NS', 'MARUTI.NS', 'NHPC.NS', 'NTPC.NS', 'NESTLEIND.NS', 'ONGC.NS', 'PIDILITIND.NS', 'PFC.NS', 'POWERGRID.NS', 'PNB.NS', 'RECLTD.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'MOTHERSON.NS', 'SHREECEM.NS', 'SHRIRAMFIN.NS', 'SIEMENS.NS', 'SBIN.NS', 'SUNPHARMA.NS', 'TVSMOTOR.NS', 'TCS.NS', 'TATACONSUM.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TECHM.NS', 'TITAN.NS', 'TORNTPHARM.NS', 'TRENT.NS', 'ULTRACEMCO.NS', 'UNIONBANK.NS', 'UNITDSPR.NS', 'VBL.NS', 'VEDL.NS', 'WIPRO.NS', 'ZOMATO.NS', 'ZYDUSLIFE.NS']\n",
    "Midcap = ['3MINDIA.NS', 'ACC.NS', 'AIAENG.NS', 'APLAPOLLO.NS', 'AUBANK.NS', 'ABBOTINDIA.NS', 'AWL.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'AJANTPHARM.NS', 'ALKEM.NS', 'APOLLOTYRE.NS', 'ASHOKLEY.NS', 'ASTRAL.NS', 'AUROPHARMA.NS', 'BSE.NS', 'BALKRISIND.NS', 'BANDHANBNK.NS', 'BANKINDIA.NS', 'MAHABANK.NS', 'BAYERCROP.NS', 'BERGEPAINT.NS', 'BDL.NS', 'BHARATFORG.NS', 'BHARTIHEXA.NS', 'BIOCON.NS', 'CGPOWER.NS', 'CRISIL.NS', 'CARBORUNIV.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COLPAL.NS', 'CONCOR.NS', 'COROMANDEL.NS', 'CUMMINSIND.NS', 'DALBHARAT.NS', 'DEEPAKNTR.NS', 'DELHIVERY.NS', 'DIXON.NS', 'EMAMILTD.NS', 'ENDURANCE.NS', 'ESCORTS.NS', 'EXIDEIND.NS', 'NYKAA.NS', 'FEDERALBNK.NS', 'FACT.NS', 'FORTIS.NS', 'GMRAIRPORT.NS', 'GICRE.NS', 'GLAND.NS', 'GLAXO.NS', 'MEDANTA.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GRINDWELL.NS', 'FLUOROCHEM.NS', 'GUJGASLTD.NS', 'HDFCAMC.NS', 'HINDPETRO.NS', 'HINDZINC.NS', 'POWERINDIA.NS', 'HONAUT.NS', 'HUDCO.NS', 'IDBI.NS', 'IDFCFIRSTB.NS', 'IRB.NS', 'INDIANB.NS', 'INDHOTEL.NS', 'IOB.NS', 'IREDA.NS', 'IGL.NS', 'INDUSTOWER.NS', 'IPCALAB.NS', 'JKCEMENT.NS', 'JSWINFRA.NS', 'JSL.NS', 'JUBLFOOD.NS', 'KPRMILL.NS', 'KEI.NS', 'KPITTECH.NS', 'KALYANKJIL.NS', 'LTF.NS', 'LTTS.NS', 'LICHSGFIN.NS', 'LINDEINDIA.NS', 'LLOYDSME.NS', 'LUPIN.NS', 'MRF.NS', 'M&MFIN.NS', 'MRPL.NS', 'MANKIND.NS', 'MARICO.NS', 'MFSL.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'METROBRAND.NS', 'MSUMI.NS', 'MPHASIS.NS', 'MUTHOOTFIN.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NAM-INDIA.NS', 'OBEROIRLTY.NS', 'OIL.NS', 'PAYTM.NS', 'OFSS.NS', 'POLICYBZR.NS', 'PIIND.NS', 'PAGEIND.NS', 'PATANJALI.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PHOENIXLTD.NS', 'POLYCAB.NS', 'POONAWALLA.NS', 'PRESTIGE.NS', 'PGHH.NS', 'RVNL.NS', 'SBICARD.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SRF.NS', 'SCHAEFFLER.NS', 'SOLARINDS.NS', 'SONACOMS.NS', 'STARHEALTH.NS', 'SAIL.NS', 'SUNTV.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUPREMEIND.NS', 'SUZLON.NS', 'SYNGENE.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATATECH.NS', 'NIACL.NS', 'THERMAX.NS', 'TIMKEN.NS', 'TORNTPOWER.NS', 'TIINDIA.NS', 'UNOMINDA.NS', 'UPL.NS', 'UBL.NS', 'IDEA.NS', 'VOLTAS.NS', 'YESBANK.NS', 'ZFCVINDIA.NS']\n",
    "Smallcap = ['360ONE.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ACE.NS', 'ABREL.NS', 'AEGISLOG.NS', 'AFFLE.NS', 'ARE&M.NS', 'AMBER.NS', 'ANGELONE.NS', 'APARINDS.NS', 'ASTERDM.NS', 'ATUL.NS', 'BEML.NS', 'BLS.NS', 'BATAINDIA.NS', 'BSOFT.NS', 'BLUESTARCO.NS', 'BRIGADE.NS', 'CESC.NS', 'CASTROLIND.NS', 'CENTRALBK.NS', 'CDSL.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CAMS.NS', 'CREDITACC.NS', 'CROMPTON.NS', 'CYIENT.NS', 'DATAPATTNS.NS', 'LALPATHLAB.NS', 'FINCABLES.NS', 'FSL.NS', 'FIVESTAR.NS', 'GRSE.NS', 'GLENMARK.NS', 'GODIGIT.NS', 'GESHIP.NS', 'GMDCLTD.NS', 'GSPL.NS', 'HBLENGINE.NS', 'HFCL.NS', 'HAPPSTMNDS.NS', 'HINDCOPPER.NS', 'IFCI.NS', 'IIFL.NS', 'IRCON.NS', 'ITI.NS', 'INDIAMART.NS', 'IEX.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'JBMA.NS', 'J&KBANK.NS', 'JWL.NS', 'JYOTHYLAB.NS', 'KPIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'LAURUSLABS.NS', 'MGL.NS', 'MANAPPURAM.NS', 'MCX.NS', 'NATCOPHARM.NS', 'NBCC.NS', 'NCC.NS', 'NSLNISP.NS', 'NH.NS', 'NATIONALUM.NS', 'NAVINFLUOR.NS', 'OLECTRA.NS', 'PNBHOUSING.NS', 'PVRINOX.NS', 'PEL.NS', 'PPLPHARMA.NS', 'RBLBANK.NS', 'RITES.NS', 'RADICO.NS', 'RAILTEL.NS', 'RKFORGE.NS', 'RAYMOND.NS', 'REDINGTON.NS', 'SHYAMMETL.NS', 'SIGNATURE.NS', 'SONATSOFTW.NS', 'SWSOLAR.NS', 'SWANENERGY.NS', 'TANLA.NS', 'TTML.NS', 'TEJASNET.NS', 'RAMCOCEM.NS', 'TITAGARH.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'UCOBANK.NS', 'WELSPUNLIV.NS', 'ZEEL.NS', 'ZENSARTECH.NS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720e5cb3-d09a-4059-916d-2fdcd12054bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Indices = ['^GSPC','^DJI','^IXIC','^NYA','^XAX','^RUT','^VIX','^FTSE','^GDAXI','^FCHI','^STOXX50E','^N100','^BFX','^GSPTSE','^HSI', '^STI','^AXJO','^AORD', '^BSESN', '^JKSE', '^KLSE','^NZ50', '^KS11', '^TWII', '000001.SS','^N225', '^BVSP', '^MXX','^IPSA','^MERV', '^TA125.TA','^CASE30','^JN0U.JO','DX-Y.NYB', '^XDB', '^XDE', '^XDN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38715d22-01ab-43ee-b399-2c7ed10b97e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supabase Credentials\n",
    "\n",
    "url = 'https://kbhdeynmboawkjtxvlek.supabase.co'\n",
    "key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImtiaGRleW5tYm9hd2tqdHh2bGVrIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDA2NDg3NjAsImV4cCI6MjA1NjIyNDc2MH0.T3L5iIn1FiBlBo5HZMqysgokD8cfOw2n3u_YCJV0DkQ'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08d9b4-a873-44a9-8fbc-579f51fb95b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b412043c-1d97-4391-9607-19857ed53b58",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab8122-535c-4a11-8977-d87d15ca4dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb0f0d-87fc-4a52-b4e9-badd02100038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d4d73da-d198-4dce-b7bc-ae1998f844ed",
   "metadata": {},
   "source": [
    "# Loading yearly data of new tickers to supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8db4a093-a09f-4138-b5fc-1aefaa661a08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 16:30:52,743 - INFO - HTTP Request: GET https://kbhdeynmboawkjtxvlek.supabase.co/rest/v1/stock_data?select=ticker%2Cdate \"HTTP/2 200 OK\"\n",
      "2025-02-28 16:30:52,755 - INFO - Fetched 1000 records from database.\n",
      "2025-02-28 16:30:52,783 - INFO - Fetching data for missing tickers: ['360ONE.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ACE.NS', 'ABREL.NS', 'AEGISLOG.NS', 'AFFLE.NS', 'ARE&M.NS', 'AMBER.NS', 'ANGELONE.NS', 'APARINDS.NS', 'ASTERDM.NS', 'ATUL.NS', 'BEML.NS', 'BLS.NS', 'BATAINDIA.NS', 'BSOFT.NS', 'BLUESTARCO.NS', 'BRIGADE.NS', 'CESC.NS', 'CASTROLIND.NS', 'CENTRALBK.NS', 'CDSL.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CAMS.NS', 'CREDITACC.NS', 'CROMPTON.NS', 'CYIENT.NS', 'DATAPATTNS.NS', 'LALPATHLAB.NS', 'FINCABLES.NS', 'FSL.NS', 'FIVESTAR.NS', 'GRSE.NS', 'GLENMARK.NS', 'GODIGIT.NS', 'GESHIP.NS', 'GMDCLTD.NS', 'GSPL.NS', 'HBLENGINE.NS', 'HFCL.NS', 'HAPPSTMNDS.NS', 'HINDCOPPER.NS', 'IFCI.NS', 'IIFL.NS', 'IRCON.NS', 'ITI.NS', 'INDIAMART.NS', 'IEX.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'JBMA.NS', 'J&KBANK.NS', 'JWL.NS', 'JYOTHYLAB.NS', 'KPIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'LAURUSLABS.NS', 'MGL.NS', 'MANAPPURAM.NS', 'MCX.NS', 'NATCOPHARM.NS', 'NBCC.NS', 'NCC.NS', 'NSLNISP.NS', 'NH.NS', 'NATIONALUM.NS', 'NAVINFLUOR.NS', 'OLECTRA.NS', 'PNBHOUSING.NS', 'PVRINOX.NS', 'PEL.NS', 'PPLPHARMA.NS', 'RBLBANK.NS', 'RITES.NS', 'RADICO.NS', 'RAILTEL.NS', 'RKFORGE.NS', 'RAYMOND.NS', 'REDINGTON.NS', 'SHYAMMETL.NS', 'SIGNATURE.NS', 'SONATSOFTW.NS', 'SWSOLAR.NS', 'SWANENERGY.NS', 'TANLA.NS', 'TTML.NS', 'TEJASNET.NS', 'RAMCOCEM.NS', 'TITAGARH.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'UCOBANK.NS', 'WELSPUNLIV.NS', 'ZEEL.NS', 'ZENSARTECH.NS']\n",
      "2025-02-28 16:31:29,092 - INFO - HTTP Request: POST https://kbhdeynmboawkjtxvlek.supabase.co/rest/v1/stock_data?columns=%22low%22%2C%22volume%22%2C%22close%22%2C%22date%22%2C%22open%22%2C%22ticker%22%2C%22high%22 \"HTTP/2 201 Created\"\n",
      "2025-02-28 16:31:29,328 - INFO - Inserted 24295 new records into the database.\n"
     ]
    }
   ],
   "source": [
    "##Â Code to load yearly data of a stock\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from supabase import create_client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Supabase credentials\n",
    "supabase = create_client(url, key)\n",
    "\n",
    "# List of stock tickers (modify to fetch only specific tickers)\n",
    "#tickers_to_fetch = Smallcap\n",
    "\n",
    "# Define date range\n",
    "today = (datetime.now()).strftime('%Y-%m-%d')\n",
    "one_year_ago = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# â **Fetch existing tickers & dates from database**\n",
    "try:\n",
    "    db_data = supabase.table(\"stock_data\").select(\"ticker\", \"date\").execute()\n",
    "    existing_records = {(row['ticker'], row['date']) for row in db_data.data}\n",
    "    logging.info(f\"Fetched {len(existing_records)} records from database.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error fetching existing tickers: {e}\")\n",
    "    existing_records = set()\n",
    "\n",
    "# â **Filter out already existing data**\n",
    "tickers_to_fetch_filtered = []\n",
    "for ticker in tickers_to_fetch:\n",
    "    for date in pd.date_range(one_year_ago, today):\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        if (ticker, date_str) not in existing_records:\n",
    "            tickers_to_fetch_filtered.append(ticker)\n",
    "            break  # Only add if at least one date is missing\n",
    "\n",
    "if not tickers_to_fetch_filtered:\n",
    "    logging.info(\"No missing data. Exiting script.\")\n",
    "    exit()\n",
    "\n",
    "logging.info(f\"Fetching data for missing tickers: {tickers_to_fetch_filtered}\")\n",
    "\n",
    "# â **Function to fetch stock data**\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    retries = 3\n",
    "    wait_time = 2  # Initial wait time\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            time.sleep(1)  # Rate limit handling\n",
    "            stock = yf.Ticker(ticker)\n",
    "            stock_data = stock.history(start=start_date, end=end_date)\n",
    "\n",
    "            if stock_data.empty:\n",
    "                logging.warning(f\"No data found for {ticker}\")\n",
    "                return None\n",
    "\n",
    "            stock_data['ticker'] = ticker\n",
    "            stock_data.columns = [col.lower() for col in stock_data.columns]\n",
    "            stock_data.reset_index(inplace=True)\n",
    "            stock_data.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "            stock_data['date'] = stock_data['date'].astype(str)\n",
    "\n",
    "            return stock_data[['date', 'open', 'high', 'low', 'close', 'volume', 'ticker']].to_dict(orient=\"records\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching data for {ticker}: {e}\")\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2  # Exponential backoff\n",
    "    return None\n",
    "\n",
    "# â **Multi-threaded fetching**\n",
    "def fetch_data_multithreaded(ticker_list, start_date, end_date):\n",
    "    results = []\n",
    "    batch_size = min(10, max(1, len(ticker_list) // 20))  # Adjust batch size dynamically\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        future_to_ticker = {executor.submit(fetch_stock_data, ticker, start_date, end_date): ticker for ticker in ticker_list}\n",
    "        for future in as_completed(future_to_ticker):\n",
    "            data = future.result()\n",
    "            if data:\n",
    "                results.extend(data)\n",
    "\n",
    "    return results\n",
    "\n",
    "# â **Fetch only missing data**\n",
    "new_data = fetch_data_multithreaded(tickers_to_fetch_filtered, one_year_ago, today)\n",
    "\n",
    "# â **Insert only new data into the database**\n",
    "if new_data:\n",
    "    try:\n",
    "        supabase.table(\"stock_data\").insert(new_data).execute()\n",
    "        logging.info(f\"Inserted {len(new_data)} new records into the database.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inserting new data: {e}\")\n",
    "else:\n",
    "    logging.info(\"No new data fetched.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cc3cd-61b8-42ad-b927-380feccdb64e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading daily data of tickers to supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8546ab-f2d8-4f5f-b86b-7d3e44601d84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new stock data to fetch.\n",
      "Fetching missing stock data from 2025-03-01 to 2025-03-01\n",
      "â Fetched data for 360ONE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for IEX.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for AADHARHFC.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for INOXWIND.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for AARTIIND.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for INTELLECT.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for AAVAS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for JBMA.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ACE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for J&KBANK.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ABREL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for JWL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for AEGISLOG.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for JYOTHYLAB.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for AFFLE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for KPIL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ARE&M.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for KARURVYSYA.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for AMBER.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for KAYNES.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ANGELONE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for KEC.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for APARINDS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for LAURUSLABS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ASTERDM.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for MGL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ATUL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for MANAPPURAM.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for MCX.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for BEML.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NATCOPHARM.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for BLS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NBCC.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for BATAINDIA.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NCC.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for BSOFT.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NSLNISP.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for BLUESTARCO.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NH.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for BRIGADE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NATIONALUM.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CESC.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for NAVINFLUOR.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CASTROLIND.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for OLECTRA.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CENTRALBK.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for PNBHOUSING.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CDSL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for PVRINOX.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CHAMBLFERT.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for PEL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CHENNPETRO.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for PPLPHARMA.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CAMS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RBLBANK.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CREDITACC.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RITES.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CROMPTON.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RADICO.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for CYIENT.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RAILTEL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for DATAPATTNS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RKFORGE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for LALPATHLAB.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RAYMOND.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for FINCABLES.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for REDINGTON.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for FSL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for SHYAMMETL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for FIVESTAR.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for SIGNATURE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for GRSE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for SONATSOFTW.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for GLENMARK.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for SWSOLAR.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for GODIGIT.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for SWANENERGY.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for GESHIP.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for TANLA.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for GMDCLTD.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for TTML.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for GSPL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for TEJASNET.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for HBLENGINE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for RAMCOCEM.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for HFCL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for TITAGARH.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for HAPPSTMNDS.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for TRIDENT.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for HINDCOPPER.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for TRITURBINE.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for IFCI.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for UCOBANK.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for IIFL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for WELSPUNLIV.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for IRCON.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ZEEL.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ITI.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for ZENSARTECH.NS (2025-03-01 to 2025-03-01)\n",
      "â Fetched data for INDIAMART.NS (2025-03-01 to 2025-03-01)\n",
      "â Stock data successfully updated in Supabase.\n",
      "â Old data deleted (older than 1 year).\n"
     ]
    }
   ],
   "source": [
    "## Code to load daily data of a stock\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "from supabase import create_client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Supabase credentials\n",
    "supabase = create_client(url, key)\n",
    "\n",
    "# List of stock tickers\n",
    "#tickers = Smallcap\n",
    "batch_size = 50  # Adjust batch size to optimize performance without hitting API limits\n",
    "\n",
    "# Get the last recorded date in the database\n",
    "latest_date_query = supabase.table(\"stock_data\").select(\"date\").order(\"date\", desc=True).limit(1).execute()\n",
    "latest_date = latest_date_query.data[0]['date'] if latest_date_query.data else None\n",
    "\n",
    "# Define todayâs date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Determine the start date (fetch only missing days)\n",
    "if latest_date:\n",
    "    last_fetched_date = datetime.strptime(latest_date, '%Y-%m-%d')\n",
    "    start_date = (last_fetched_date + timedelta(days=1)).strftime('%Y-%m-%d')  # Start from next missing date\n",
    "else:\n",
    "    start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')  # Fetch last 1 year if no data exists\n",
    "\n",
    "# Ensure we only fetch data if needed\n",
    "if start_date >= today:\n",
    "    print(\"No new stock data to fetch.\")\n",
    "    exit()\n",
    "\n",
    "# Function to fetch historical stock data with rate limit handling\n",
    "def fetch_stock_data(tickers_batch, start_date, end_date, results):\n",
    "    for ticker in tickers_batch:\n",
    "        retries = 3  # Retry up to 3 times if request fails\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                time.sleep(1.5)  # Avoid hitting API rate limits\n",
    "                stock = yf.Ticker(ticker)\n",
    "                stock_data = stock.history(start=start_date, end=end_date)\n",
    "\n",
    "                if stock_data.empty:\n",
    "                    print(f\"Warning: No data found for {ticker}\")\n",
    "                    break  # No need to retry if no data exists\n",
    "\n",
    "                stock_data['ticker'] = ticker\n",
    "                stock_data.columns = [col.lower() for col in stock_data.columns]\n",
    "                stock_data = stock_data.reset_index()\n",
    "                stock_data.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "                stock_data['date'] = stock_data['date'].astype(str)\n",
    "\n",
    "                required_columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'ticker']\n",
    "                results.extend(stock_data[required_columns].to_dict(orient=\"records\"))\n",
    "\n",
    "                print(f\"â Fetched data for {ticker} ({start_date} to {end_date})\")\n",
    "                break  # Success, exit retry loop\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"â ï¸ Failed to fetch data for {ticker}: {e}\")\n",
    "                retries -= 1\n",
    "                time.sleep(3)  # Wait 3 seconds before retrying\n",
    "\n",
    "# â Fetch & update missing stock data using multithreading\n",
    "print(f\"Fetching missing stock data from {start_date} to {today}\")\n",
    "\n",
    "updated_data = []\n",
    "threads = []\n",
    "\n",
    "for i in range(0, len(tickers), batch_size):\n",
    "    batch = tickers[i:i + batch_size]\n",
    "    thread = threading.Thread(target=fetch_stock_data, args=(batch, start_date, today, updated_data))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "    time.sleep(2)  # Short delay to prevent excessive API calls\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "# Insert the fetched data into the database\n",
    "if updated_data:\n",
    "    try:\n",
    "        supabase.table(\"stock_data\").insert(updated_data).execute()\n",
    "        print(\"â Stock data successfully updated in Supabase.\")\n",
    "    except Exception as e:\n",
    "        print(f\"â ï¸ Error inserting stock data: {e}\")\n",
    "\n",
    "# â Delete data older than 1 year\n",
    "one_year_ago = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "\n",
    "try:\n",
    "    supabase.table(\"stock_data\").delete().filter(\"date\", \"lt\", one_year_ago).execute()\n",
    "    print(\"â Old data deleted (older than 1 year).\")\n",
    "except Exception as e:\n",
    "    print(f\"â ï¸ Error deleting old data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23d77e-6d29-497e-a6c2-d0fec44695d6",
   "metadata": {},
   "source": [
    "# Remove data of tickers from supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17351271-7e05-4e47-bb3d-72733b226fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Example list of tickers to be deleted (Replace with your own list)\n",
    "#removed_tickers = [\"AAPL\", \"GOOGL\", \"TSLA\", \"MSFT\", \"AMZN\"]  # Add the tickers you want to remove\n",
    "\n",
    "# Function to delete tickers in batches\n",
    "def delete_tickers_batch(batch):\n",
    "    try:\n",
    "        supabase.table(\"stock_data\").delete().in_(\"ticker\", batch).execute()\n",
    "        print(f\"â Successfully deleted {len(batch)} tickers from Supabase: {batch}\")\n",
    "    except Exception as e:\n",
    "        print(f\"â ï¸ Error deleting tickers {batch}: {e}\")\n",
    "\n",
    "# â Multi-threaded deletion of removed tickers\n",
    "if removed_tickers:\n",
    "    print(f\"ð Removing {len(removed_tickers)} tickers from database...\")\n",
    "\n",
    "    batch_size = 50  # Adjust batch size as needed\n",
    "    threads = []\n",
    "\n",
    "    for i in range(0, len(removed_tickers), batch_size):\n",
    "        batch = removed_tickers[i:i + batch_size]\n",
    "        thread = threading.Thread(target=delete_tickers_batch, args=(batch,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        time.sleep(1)  # Short delay to prevent overwhelming the API\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"â All removed tickers successfully deleted from Supabase.\")\n",
    "else:\n",
    "    print(\"No tickers to remove.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d402b5d-ec29-438c-94fa-8ddedbacf7f7",
   "metadata": {},
   "source": [
    "# Test: # Extracting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a07eee-e505-4dd7-9276-d9cbf195cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = supabase.table(\"stock_data\").select(\"*\").execute()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if response.data:\n",
    "        df = pd.DataFrame(\n",
    "    supabase.table(\"stock_data\")\n",
    "    .select(\"*\")\n",
    "    .filter(\"ticker\", \"eq\", \"NTPC.NS\")\n",
    "    .execute()\n",
    "    .data\n",
    ")\n",
    "        print(\"Fetched data successfully:\")\n",
    "        print(df.head())  # Display first few rows\n",
    "    else:\n",
    "        print(\"No data found in the database.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
